{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b9227f7",
   "metadata": {},
   "source": [
    "# Mise à disposition du jeu de données stroke_dataset via une API REST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02037c20",
   "metadata": {},
   "source": [
    "## Description du dataset\n",
    "\n",
    "Le jeu de données utilisé provient de Kaggle : [Stroke Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset).  \n",
    "Il contient des données de patients avec différentes caractéristiques médicales et sociales, ainsi que l'information si le patient a subi un accident vasculaire cérébral (AVC) ou non.\n",
    "\n",
    "Télécharger les données et ajouter les dans un dossier data/.\n",
    "\n",
    "Les colonnes des données sont :  \n",
    "- `id` : Identifiant unique du patient  \n",
    "- `gender` : Sexe  \n",
    "- `age` : Âge  \n",
    "- `hypertension` : Présence d'hypertension (0 ou 1)  \n",
    "- `heart_disease` : Présence de maladie cardiaque (0 ou 1)  \n",
    "- `ever_married` : Statut marital  \n",
    "- `work_type` : Type d'emploi  \n",
    "- `Residence_type` : Urbaine ou rurale  \n",
    "- `avg_glucose_level` : Moyenne du taux de glucose  \n",
    "- `bmi` : Indice de masse corporelle  \n",
    "- `smoking_status` : Statut tabagique  \n",
    "- `stroke` : Présence d'AVC (0 ou 1)\n",
    "\n",
    "## Projet\n",
    "\n",
    "Vous devez exposer les données patients du jeu de données via une API REST afin que les données soit utilisables par d'autres équipes (médecins, data science, étude, etc.).\n",
    "\n",
    "Cette API REST sera développée avec FastAPI et les spécifications sont les suivantes :\n",
    "| Méthode | Endpoint                                      | Fonctionnalité                                                                                                    |\n",
    "| ------- | --------------------------------------------- | ----------------------------------------------------------------------------------------------------------------- |\n",
    "| `GET`   | `/patients/{id}`                              | Récupère les détails d’un patient donné (via son identifiant unique)                                              |\n",
    "| `GET`   | `/patients?stroke=1&gender=Female&max_age=60` | Renvoie les patients filtrés selon plusieurs critères : AVC (oui/non), genre, âge maximal                         |\n",
    "| `GET`   | `/stats/`                                     | Fournit des statistiques agrégées sur les patients (ex. : nb total de patients, âge moyen, taux d’AVC, répartition hommes/femmes, etc.) |\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Quelques définitions\n",
    "\n",
    "\n",
    "1. Qu’est-ce qu’une API REST ?\n",
    "\n",
    "- API signifie Application Programming Interface (Interface de Programmation d’Application). C’est un ensemble de règles et de protocoles qui permettent à des logiciels de communiquer entre eux.\n",
    "- REST signifie Representational State Transfer. C’est un style architectural pour concevoir des services web.\n",
    "Il en existe d'autres mais REST est celui que vous rencontrerez le plus souvent.\n",
    "- Vous avez utilisé une API REST via l'API Google Books.\n",
    "\n",
    "- A quoi sert une API REST ?\n",
    "\n",
    "    - Permet à différentes applications de communiquer facilement, même si elles sont écrites dans des langages différents.\n",
    "    - Permet d’accéder à des services distants (ex : bases de données, services web) de manière standardisée.\n",
    "    - Facilite la création d’applications modulaires et évolutives (front-end, back-end, mobile, etc.)\n",
    "\n",
    "2. Principes clés d’une API REST\n",
    "\n",
    "- a. Utilisation du protocole HTTP\n",
    "Les échanges entre client et serveur utilisent des méthodes HTTP standard comme :\n",
    "\n",
    "    - GET : pour récupérer des données\n",
    "    - POST : pour envoyer ou créer des données\n",
    "    - PUT : pour mettre à jour des données\n",
    "    - DELETE : pour supprimer des données\n",
    "\n",
    "- b. Accès aux ressources via des URLs\n",
    "\n",
    "Chaque ressource (par exemple un livre, un utilisateur) est accessible via une URL unique.\n",
    "\n",
    "Exemple fictif:\n",
    "    https://api.example.com/books/123 pour accéder au livre d’identifiant 123.\n",
    "\n",
    "- c. Stateless (sans état)\n",
    "\n",
    "Le serveur ne conserve aucune information sur le client entre deux requêtes. Chaque requête doit contenir toutes les informations nécessaires.\n",
    "\n",
    "- d. Représentations des données\n",
    "\n",
    "Les données sont envoyées et reçues généralement en format JSON ou XML, qui sont faciles à lire et à manipuler.\n",
    "\n",
    "- e. Utilisation de codes status HTTP\n",
    "\n",
    "Chaque réponse du serveur est accompagnée d’un code HTTP indiquant le résultat de la requête. (cf [liste des codes](https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Status))\n",
    "\n",
    "## Outils utilisés\n",
    "1. FastAPI\n",
    "\n",
    "FastAPI est un framework Python moderne, rapide et très utilisé dans le milieu professionnel pour construire des API REST. \n",
    "\n",
    "Il permet :\n",
    "- une définition simple des routes et des paramètres  \n",
    "- La génération automatique de documentation interactive (Swagger UI)  \n",
    "- FastAPI lit les requêtes entrantes, les traite avec ton code Python, et retourne une réponse HTTP (en JSON).\n",
    "\n",
    "2. Uvicorn : exécute l'application FastAPI\n",
    "\n",
    "- Uvicorn est un serveur ASGI (Asynchronous Server Gateway Interface) : c'est une interface standard pour gérer les requêtes de manière asynchrone et performante, notamment utile pour les applications modernes.\n",
    "- Il attend les requêtes HTTP (par exemple depuis un navigateur), les transmet à FastAPI, et renvoie la réponse.\n",
    "- Uvicorn permet à l'API de fonctionner : sans Uvicorn ou un autre serveur, FastAPI ne peut pas fonctionner.\n",
    "\n",
    "\n",
    "3. Swagger UI : l’interface de doc et test interactive\n",
    "\n",
    "- Swagger UI est généré automatiquement par FastAPI.\n",
    "- C’est une interface web qui permet de :\n",
    "    - Voir toutes les routes disponibles dans l'API\n",
    "    - Tester les routes en envoyant des requêtes sans écrire de code (bouton try it out)\n",
    "    - Voir les paramètres attendus et les formats de réponse\n",
    "    \n",
    "4. Résumé des interactions\n",
    "\n",
    "- Tester la route de base de l'API grâce à la commande :\n",
    "```bash\n",
    "    poetry run fastapi dev stroke_api/main.py\n",
    "```\n",
    "\n",
    "--> Qu'est-ce qu'il se passe derrière cette commande ?\n",
    "\n",
    "- Uvicorn démarre un serveur local\n",
    "- FastAPI génère automatiquement une interface : Swagger UI, accessible sur http://127.0.0.1:8000/docs qui affiche toutes les routes définies dans le code python FastAPI\n",
    "- Quand on clique sur \"Try it out\" dans Swagger UI, Swagger envoie une requête HTTP au serveur (ici Uvicorn)\n",
    "- Le serveur (Uvicorn) la reçoit, l’envoie à FastAPI, qui traite et renvoie une réponse\n",
    "- Swagger UI affiche la réponse de l’API (par ex : liste de patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02e38a2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Import des bibliothèques utiles au projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548f6eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cf9064",
   "metadata": {},
   "source": [
    "## 1. Prétraitement des données / Data preprocessing\n",
    "\n",
    "Les données réelles sont rarement prêtes à être utilisées directement. Elles peuvent contenir des erreurs, des valeurs manquantes, des doublons, des formats incohérents, ou ne pas être adaptées au modèle ou au système cible.\n",
    "\n",
    "Le prétraitement consiste à nettoyer, structurer et transformer les données brutes avant de les exploiter dans un projet (modèle IA, API, visualisation, etc.).\n",
    "\n",
    "Vous avez déjà prétraité des données, petit rappel des éléments sur lesquels travailler dans un prétraitment classique et les méthodes pandas qu'il est possible d'utiliser pour les différentes étapes (des exeples d'utilisation des méthodes pandas sont disponibles dans la doc) : \n",
    "- explorer les données pour identifier les types de données, valeurs manquantes, incohérence ([info](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html), [dtypes](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dtypes.html))\n",
    "- adapter les types si nécessaire ([astypes](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html))\n",
    "- identifier les doublons et les supprimer s'il y en a ([duplicated](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.duplicated.html), [drop_duplicates](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html))\n",
    "- traiter les valeurs manquantes s'il y en a ([fillna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html), [dropna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html), [replace](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html))\n",
    "- identifier les incohérences éventuelles (valeurs aberrantes/outliers) en vérifiant si les valeurs min, max, moyennes sont raisonnables (recherche internet si nécessaire) ([describe](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html)), et les traiter.\n",
    "- Traiter les valeurs aberrantes si vous en détectez ([loc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html) pour récupérer les lignes qui répondent à une certaine condition, cf exemple ci-dessous)\n",
    "\n",
    "\n",
    "**Exemple df.loc :**\n",
    "\n",
    "Récupérer toutes les lignes de df telles que la valeur de \"nom de colonne\" >= 0\n",
    "\n",
    "```df_subset = df.loc[stroke_data_df['nom de colonne'] >= 0]```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb65710",
   "metadata": {},
   "source": [
    "---\n",
    "### **TODO**\n",
    "1.a. Prétraiter les données du dataset.\n",
    "\n",
    "\n",
    "1.b. Documenter dans le README.md :\n",
    "- Les étapes de prétraitement,\n",
    "- Justification des choix concernant le traitement des valeurs manquantes (si besoin),\n",
    "- Liste des valeurs raisonnables utilisées pour détecter les valeurs aberrantes, \n",
    "- Justification des choix pour traiter les valeurs aberrantes (si besoin).\n",
    "\n",
    "2.a. Chercher des infos sur le format de fichier parquet et indiquer les sources consultées : \n",
    "- https://www.datacamp.com/fr/tutorial/apache-parquet  \n",
    "\n",
    "- https://www.icem7.fr/cartographie/parquet-devrait-remplacer-le-format-csv/  \n",
    "\n",
    "- https://pythonds.linogaliana.fr/content/manipulation/05_parquet_s3.html#:~:text=Le%20format%20Parquet%20est%20un,pro%C3%A9minents%20sont%20Arrow%20et%20DuckDB%20  \n",
    "\n",
    "- Différence principale avec le format csv ?  \n",
    "    - Le format csv est plus lourd (non compressé). Parquet est orienté colonne là où csv est orienté lignes, ce qui permet de charger uniquement les colonnes utiles à l'analyse. Il conserve les types de données (float, int, etc.).\n",
    "\n",
    "- Dans quels cas l'utiliser ?  \n",
    "    - Pour des traitements Big Data, besoin de performance, données volumineuses.\n",
    "\n",
    "- Pourquoi c'est un format adapté aux gros volumes de données ?\n",
    "    - Stockage par colonne = accès plus rapide + moins de données à charger.\n",
    "    - Très bonne compression = gain d’espace disque.\n",
    "    - Lecture sélective = gain de performance.\n",
    "    - Compatible avec outils distribués = scalabilité.\n",
    "\n",
    "\n",
    "\n",
    "2.b. Sauvegarder les données prétraiteées dans un fichier parquet ([to_parquet](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_parquet.html)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b391b2",
   "metadata": {},
   "source": [
    "### Prétraitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f760f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des données\n",
    "try:\n",
    "\tdf = pd.read_csv('../data/healthcare-dataset-stroke-data.csv')\n",
    "\tprint(df.head())\n",
    "except FileNotFoundError: # Gestion de l'erreur si le fichier n'est pas trouvé\n",
    "\tprint(\"Le fichier '../data/healthcare-dataset-stroke-data.csv' est introuvable. Veuillez le télécharger depuis Kaggle et le placer dans le dossier 'data/'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b658c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On affiche les informations du dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be78697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On vérifie s'il y a des doublons dans le dataframe et on les supprimes\n",
    "df_duplicated = df.duplicated()\n",
    "print(f\"Nombre de doublons : {df_duplicated.sum()}\")\n",
    "\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92868785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On calcul le nombre de valeurs manquantes dans la colonne 'bmi'\n",
    "df_bmi = df['bmi'].isnull().sum()\n",
    "print(f\"Nombre de valeurs manquantes dans la colonne 'bmi' : {df_bmi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a07552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour détecter les valeurs aberrantes dans le dataframe\n",
    "def aberrante_values(df):\n",
    "    \"\"\"\n",
    "    Fonction pour détecter les valeurs aberrantes dans le dataframe.\n",
    "    Cette fonction vérifie si la colonne 'work_type' est présente et si l'âge est inférieur à 18 ans.\n",
    "    Si c'est le cas, elle remplace la valeur dans 'work_type' par 'children' si l'âge est inférieur à 18 ans et que 'work_type' n'est pas 'children'.\n",
    "    On vérifie et traite également les valeurs 'Unknown' dans la colonne 'smoking_status' selon l'âge < ou > 18 ans. \n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): Le dataframe à analyser.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Le dataframe avec les valeurs aberrantes traitées.\"\"\"\n",
    "    \n",
    "    if 'work_type' in df.columns and 'age' in df.columns:\n",
    "        df.loc[(df['age'] < 18) & (df['work_type'] != 'children'), 'work_type'] = 'children'\n",
    "    \n",
    "    if 'smoking_status' in df.columns and 'age' in df.columns:\n",
    "        df.loc[(df['age'] < 18) & (df['smoking_status'] == 'Unknown'), 'smoking_status'] = 'never smoked'\n",
    "        df.loc[(df['age'] >= 18) & (df['smoking_status'] == 'Unknown'), 'smoking_status'] = 'not specified'\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = aberrante_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3110e8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On calcule et affiche la mediane pour 'bmi'\n",
    "print(df.groupby(['gender', 'age', 'Residence_type', 'work_type'])['bmi'].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437dfa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On applique la mediane pour les NaN dans 'bmi'\n",
    "df['bmi'] = df.groupby(['gender', 'age', 'Residence_type', 'work_type'])['bmi'].transform(lambda x: round(x.fillna(x.median()), 1))\n",
    "print(df['bmi'])\n",
    "\n",
    "bmi = df['bmi'].isnull().sum()\n",
    "print(f\"----------------{bmi}----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb91a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On applique une autre mediane moins restrictive pour les valeurs qui n'ont pas reçu la précédente mediane'bmi'\n",
    "df['bmi'] = df.groupby(['gender', 'work_type'])['bmi'].transform(lambda x: round(x.fillna(x.median()), 1))\n",
    "print(df['bmi'])\n",
    "\n",
    "bmi = df['bmi'].isnull().sum()\n",
    "print(f\"----------------{bmi}----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db92d6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification valeurs aberrantes sur le glucose\n",
    "if 'avg_glucose_level' in df.columns:\n",
    "    df_glucose = df.loc[(df['avg_glucose_level'] < 50) | (df['avg_glucose_level'] > 280)]\n",
    "    print(df_glucose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2493f7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification valeurs aberrantes sur le bmi\n",
    "if 'bmi' in df.columns:\n",
    "    df_bmi = df.loc[(df['bmi'] < 10) | (df['bmi'] > 80)]\n",
    "    print(df_bmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7d10d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du df dans un fichier .parquet\n",
    "df.to_parquet('../data/stroke_data.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dfaae1",
   "metadata": {},
   "source": [
    "-----\n",
    "## Développement de l'API\n",
    "\n",
    "A présent que les données sont propres, on peut débuter la création de l'API.\n",
    "\n",
    "Pour cela, vous allez avoir besoin de quelques fonctions permettant de filtrer les données.\n",
    "\n",
    "Vous allez les définir ci-dessous, ce qui vous permettra de les tester puis les fonctions seront reportées dans le fichier filters.py."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c2b0d0",
   "metadata": {},
   "source": [
    "## Route `/patients/`\n",
    "- Cette route retourne une liste filtrée de patients\n",
    "- On souhaite pouvoir filtrer par `gender`, `stroke` ou `max_age`\n",
    "\n",
    "L'objectif est ici de définir une fonction python qui prend en entrée les paramètres optionnels : _gender_, *stroke*, *max_age* et qui renvoie un dictionnaire filtré des données.\n",
    "\n",
    "On décompose la rédaction de cette fonction en plusieurs étapes. \n",
    "\n",
    "Dans un premier temps, écrire et tester les filtres que l'on souhaite appliquer sur les données (utiliser [loc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b25d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer le dataframe pour ne garder que les patients pour lesquels \"stroke=1\"\n",
    "def filtred_stroke(df, stroke):\n",
    "    if 'stroke' in df.columns:\n",
    "        return df.loc[df['stroke'] == stroke]\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "df_stroke = filtred_stroke(df, 1)\n",
    "print(df_stroke)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eca4b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les données pour ne garder que les patients pour lesquels \"gender=\"male\"\n",
    "def filtred_gender(df, gender):\n",
    "    if 'gender' in df.columns:\n",
    "        return df.loc[df['gender'].str.lower() == gender.lower()]\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "df_gender = filtred_gender(df, 'male')\n",
    "print(df_gender)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bac1cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les données pour ne garder que les patients tels que \"age <= max_age\"\n",
    "def filtred_max_age(df, max_age):\n",
    "    if 'age' in df.columns:\n",
    "        return df.loc[df['age'] <= max_age]\n",
    "    else:\n",
    "        return df \n",
    "\n",
    "df_max_age = filtred_max_age(df, max_age=50)\n",
    "print(df_max_age)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9f1928",
   "metadata": {},
   "source": [
    "Appliquer successivement les 3 filtres au sein d'une fonction qui prend en entrée le dataframe, _stroke_, _gender_, _max_age_ et qui renvoie une liste de dictionnaire de patients (utiliser la méthode pandas [to_dict](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_dict.html)).\n",
    "\n",
    "Exemple\n",
    "```\n",
    "[{'id': 9046,\n",
    "  'gender': 'Male',\n",
    "  'age': 67.0,\n",
    "  ...\n",
    "  'smoking_status': 'formerly smoked',\n",
    "  'stroke': 1},\n",
    " {'id': 31112,\n",
    "  'gender': 'Male',\n",
    "  'age': 80.0,\n",
    "  ...\n",
    "  'smoking_status': 'formerly smoked',\n",
    "  'stroke': 1}]\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c364a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_patient(df, max_age, gender, stroke):\n",
    "    df_filtered = filtred_stroke(df, stroke)\n",
    "    df_filtered = filtred_gender(df_filtered, gender)\n",
    "    df_filtered = filtred_max_age(df_filtered, max_age)\n",
    "    return df_filtered\n",
    "\n",
    "df_result = filter_patient(df, stroke = 1, gender='male', max_age=50)\n",
    "\n",
    "df_result.to_dict('records')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85017c8f",
   "metadata": {},
   "source": [
    "A présent on souhaite ajouter des informations sur les types des paramètres et valeurs de retour de la fonction pour faciliter sa compréhension et son utilisation, ce qu’on appelle l’annotation de type (type hinting).\n",
    "\n",
    "Cette pratique facilite la lecture et la maintenance du code.\n",
    "\n",
    "Quels changements pour la fonction ?\n",
    "\n",
    "A la suite de chaque paramètre, on ajoute le type attendu pour le paramètre. À la suite des paramètres on ajoute le type de ce que qui est retourné par la fonction, dans l'exemple ici : \n",
    "\n",
    "```def filter_patient(stroke_data_df: pd.DataFrame, gender: str, etc) -> list[dict]```\n",
    "\n",
    "Ajouter les types dans la définition de la fonction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b7f0a",
   "metadata": {},
   "source": [
    "Tester la fonction en ne mettant pas de valeur pour *max_age*.\n",
    "\n",
    "Que se passe-t-il ?  \n",
    "On a une erreur de type TypeError : Un argument est attendu pour max_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78da71a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_patient(df: pd.DataFrame, gender: str, stroke: int, max_age: int) -> list[dict]:\n",
    "    df_filtered = filtred_stroke(df, stroke)\n",
    "    df_filtered = filtred_gender(df_filtered, gender)\n",
    "    df_filtered = filtred_max_age(df_filtered, max_age)\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "df_result = filter_patient(df, stroke = 1, gender='Male')\n",
    "\n",
    "df_result.to_dict('records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956bca5f",
   "metadata": {},
   "source": [
    "Dans la fonction écrite ci-dessus, chaque paramètre est obligatoire. \n",
    "\n",
    "On souhaite pouvoir filtrer les patients sur 0, 1 ou 2 des paramètres de la fonction (filtrer seulement sur *max_age*  mais ne pas appliquer de filtres sur _gender_ et _stroke_ par exemple).\n",
    "\n",
    "On peut rendre optionnel les paramètres d'un fonction en choisissant une valeur par défault. Si on utilise la fonction en n'utilisant pas ces paramètres alors la valeur par défault est utilisé.\n",
    "\n",
    "Copier coller votre fonction ci-dessous et ajouter en paramètre : `max_age=None`\n",
    "\n",
    "et ajouter la condition suivante **avant le filtre** sur `max_age` : \n",
    "\n",
    "```if max_age is not None : ``` \n",
    "\n",
    "Si la fonction _filter_patient_ est appelée sans argument *max_age*, alors le filtre sur *max_age* n'est pas appliqué. \n",
    "\n",
    "Il est tout à fait possible de définir une valeur par défault par exemple 30 ans : dans ce cas si la fonction est appelée sans argument *max_age*, alors par défault on filtre les patients ayant moins de 30 ans.\n",
    "\n",
    "**ATTENTION :** Les paramètres optionnels doivent toujours être à la fin de la liste de paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f987b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction filter_patient paramètre max_age optionnel\n",
    "from typing import Optional\n",
    "def filter_patient(df: pd.DataFrame, gender: str, stroke: int, max_age: Optional[int] = None) -> list[dict]:\n",
    "    df_filtered = df.copy()\n",
    "    \n",
    "    df_filtered = filtred_stroke(df, stroke)\n",
    "    df_filtered = filtred_gender(df_filtered, gender)\n",
    "    \n",
    "    if max_age is not None:\n",
    "        df_filtered = filtred_max_age(df_filtered, max_age)\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "df_result = filter_patient(df, stroke = 1, gender='male', max_age = 50)\n",
    "\n",
    "df_result.to_dict('records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23084a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test fonction sans argument max_age\n",
    "from typing import Optional\n",
    "def filter_patient(df: pd.DataFrame, gender: str, stroke: int, max_age: Optional[int] = None) -> list[dict]:\n",
    "    df_filtered = df.copy()\n",
    "    \n",
    "    df_filtered = filtred_stroke(df, stroke)\n",
    "    df_filtered = filtred_gender(df_filtered, gender)\n",
    "    \n",
    "    if max_age is not None:\n",
    "        df_filtered = filtred_max_age(df_filtered, max_age)\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "df_result = filter_patient(df, stroke = 1, gender='male')\n",
    "\n",
    "df_result.to_dict('records')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe7f5de",
   "metadata": {},
   "source": [
    "Ajouter des valeurs par défault et les conditions pour chaque filtre.\n",
    "\n",
    "Pour les types, on indique qu'il s'agit de paramètres optionels en utilisant le module python _typing_\n",
    "\n",
    "```\n",
    "from typing import Optional\n",
    "def filter_patient(stroke_data_df: pd.DataFrame, gender: Optional[str] = None,etc)\n",
    "```\n",
    "\n",
    "Adapter les types en utilisant ce modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55db8ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction avec ajout de paramètres par défault et de type\n",
    "def filter_patient(\n",
    "    df: pd.DataFrame, \n",
    "    gender: Optional[str] = None, \n",
    "    stroke: Optional[int] = None, \n",
    "    max_age: Optional[int] = None\n",
    ") -> list[dict]:\n",
    "    \n",
    "    df_filtered = df.copy()\n",
    "\n",
    "    if gender is not None:\n",
    "        df_filtered = filtred_gender(df_filtered, gender)\n",
    "    if stroke is not None:\n",
    "        df_filtered = filtred_stroke(df_filtered, stroke)\n",
    "    if max_age is not None:\n",
    "        df_filtered = filtred_max_age(df_filtered, max_age)\n",
    "    if df_filtered.empty:\n",
    "        print(\"Aucun patient ne correspond aux critères sélectionnés.\")\n",
    "    return df_filtered.to_dict('records')\n",
    "\n",
    "\n",
    "filter_patient(df, stroke = 1, gender = 'female', max_age = 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c073eb",
   "metadata": {},
   "source": [
    "Tester la fonction sans argument pour les filtres, elle doit donc renvoyer le dataframe non filtré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ffbfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test fonction sans argument pour les filtres\n",
    "filter_patient(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7816b86",
   "metadata": {},
   "source": [
    "Cette fonction va être utilisée dans la définition de l'API pour créer une route qui permette d'accéder à des données filtrées sur les patients.\n",
    "\n",
    "Dans le fichier de définition de l'API, toutes les fonctions vont travailler sur les données du fichier. \n",
    "\n",
    "Pour alléger les fonctions on va donc utiliser une **variable globale** pour les données et supprimer le paramètre `df` de la fonction.\n",
    "\n",
    "On lit les données en début de fichier puis on travaille au sein des fonctions sur une copie du dataframe de données.\n",
    "\n",
    "\n",
    "**En résumé les modifications à faire sont :**\n",
    "\n",
    "\n",
    "- Supprimer le paramètre df de la fonction,\n",
    "- Ajouter en début de fonction :  \n",
    "```df = stroke_data_df.copy()```\n",
    "\n",
    "1. Dans le fichier filters.py, il suffit d'ajouter : \n",
    "- lecture du fichier de données prétraitée dans la variable *df* en début de fichier (utiliser pandas),\n",
    "- @app.get(\"/patients/\") pour définir le route,\n",
    "puis la fonction.\n",
    "\n",
    "2. Dans le fichier api.py: appeler la fonction dans la route correspondante.\n",
    "\n",
    "Tester la route avec \n",
    "\n",
    "```poetry run fastapi dev stroke_api/main.py```\n",
    "\n",
    "http://127.0.0.1:8000/docs : utiliser la fonctionnalité Try it out pour tester la route."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b80fee",
   "metadata": {},
   "source": [
    "---\n",
    "## Autres routes\n",
    "\n",
    "De la même manière, créer les fonctions appropriées pour la création de :\n",
    "- la route `/patients/{id}` : Récupère les détails d’un patient donné (via son identifiant unique) \n",
    "\n",
    "- la route `/stats/` : Fournit des statistiques agrégées sur les patients (ex. : nb total de patients, âge moyen, taux d’AVC, répartition hommes/femmes).\n",
    "\n",
    "- Lister les tâches à faire sous forme d'issue github : travailler sur une branche différentes pour l'ajout de chacune des routes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stroke-api-vui5jyj7-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
